This repo is a collection of all the different ways I tried to fine-tune the LlaMA-135M model, and to try and get it to be a good replacement for the brains of the chatbot in the Speak Activity.

I will have each directory for each training attempt. Each such directory will include the training script and a `MODELS.md` file that links to different HF repos that have the model files in different formats and quantizations.

There will also be a common inference script depending on the model type. 
